DOF: Moving along all directions
Timestep: 1e-3
Aerodynamics: Mujoco built-in
Reward: if terminated: if timestep < 1000: reward -= 10
Launch Control: if timestep < 100
I/O History: Short(4) / Obs (97,)

net_arch = {'pi': [128,128],
            'vf': [128,128]}

model = PPO('MlpPolicy', 
            env=env,
            learning_rate=1e-4,
            n_steps=512, # The number of steps to run for each environment per update / 2048
            batch_size=256,
            gamma=0.98,  # 0.99 # look forward 1.65s
            gae_lambda=0.95,
            clip_range=0.2,
            ent_coef=0.05, # Makes PPO explore
            verbose=1,
            policy_kwargs={'net_arch':net_arch},
            tensorboard_log=log_path,
            device='mps'
            )